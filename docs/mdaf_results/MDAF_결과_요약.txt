
================================================================================
MDAF 학습 결과 요약
================================================================================

프로젝트: Multi-Domain Attention Fusion (MDAF) for CTR Prediction
데이터셋: Taobao (카테고리 필터링 적용)
날짜: 2025-11-11

================================================================================
최종 성능
================================================================================

Best Model: Epoch 1
  - Val AUC: 0.6007
  - Train AUC: 0.5363
  - Train-Val Gap: -0.0644

베이스라인 비교:
  - BST (Baseline): 0.5711
  - MDAF (최종): 0.6007
  - 개선: +0.0296 (+5.2%)

================================================================================
개선 과정
================================================================================

1. 원본 데이터:              0.5826
2. + 빈 시퀀스 필터링:       0.5826 (변화 없음)
3. + 카테고리 필터링:        0.5931 (+0.0105, +1.8%)
4. + 하이퍼파라미터 조정:    0.6007 (+0.0076, +1.3%)
   ──────────────────────────────────────
   총 개선:                  +0.0181 (3.1%)
   BST 대비:                 +0.0296 (5.2%)

================================================================================
하이퍼파라미터 (최적화됨)
================================================================================

- Learning rate: 0.0005
- Dropout: 0.15
- Weight decay: 1e-5
- Label smoothing: 0.01
- Gradient clip norm: 1.0
- Warmup epochs: 2
- Early stopping patience: 5

================================================================================
데이터 전처리
================================================================================

원본 데이터:
  - Train: 1,052,081 샘플
  - Val: 225,446 샘플

빈 시퀀스 제거:
  - Train: 915,915 샘플 (-13.0%)
  - Val: 196,361 샘플 (-12.9%)

카테고리 필터링 (최종):
  - Train: 473,044 샘플 (-48.3%)
  - Val: 101,609 샘플 (-48.3%)

필터링 기준:
  - 타겟 카테고리가 히스토리에 있는 샘플만 사용
  - 히스토리-타겟 연관성: 1.6% → 100%

================================================================================
주요 발견
================================================================================

✅ 성공 요인:
  1. 카테고리 기반 필터링으로 연관성 개선
  2. Dropout 감소 (0.25→0.15)로 언더피팅 해소
  3. Early stopping이 오버피팅 방지

⚠️ 한계점:
  1. Val AUC 0.6007은 여전히 낮음 (실용적 수준 아님)
  2. 심각한 오버피팅 (Epoch 6: Train 0.9970 vs Val 0.5436)
  3. Taobao 데이터의 순차 패턴이 약함
  4. Mamba4Rec의 효과가 제한적

================================================================================
오버피팅 분석
================================================================================

Epoch별 Train-Val Gap:
  Epoch 1: -0.0644 (건강)
  Epoch 2: +0.2027 (오버피팅 시작)
  Epoch 3: +0.3746 (심각)
  Epoch 4: +0.4291 (매우 심각)
  Epoch 5: +0.4499 (극심)
  Epoch 6: +0.4534 (극심)

→ Epoch 1이 Best, Early stopping 정상 작동

================================================================================
모델 구조
================================================================================

MDAF Architecture:
  - DCNv3: 정적 특징 교차 학습
  - Mamba4Rec: 순차 행동 모델링
  - Fusion Gate: 두 모듈의 출력 결합

총 파라미터: 45,969,365

Gate 가중치 (Epoch 1):
  - Mean: 0.1766
  - Std: 0.0165
  - Range: [0.1053, 0.2561]
  → DCNv3에 더 많이 의존

================================================================================
결론
================================================================================

MDAF는 BST 대비 5.2% 개선을 보였으나, Taobao 데이터셋의
약한 순차 패턴으로 인해 Mamba4Rec의 효과가 제한적입니다.

권장 사항:
  1. 더 강한 순차 패턴을 가진 데이터셋 (e.g., MovieLens) 시도
  2. Criteo에서 DCNv3 단독 성능 검증
  3. 정규화 전략 추가 연구 (Mixup, CutMix 등)
  4. 하이브리드 접근 (item + category 신호 결합)

================================================================================
