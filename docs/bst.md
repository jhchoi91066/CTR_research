물론입니다. 논문 연구 계획에 맞춰 BST(Behavior Sequence Transformer) 모델을 정확하게 구현하는 데 필요한 핵심 정보를 아키텍처 중심으로 상세하게 정리해 드리겠습니다.

### **BST(Behavior Sequence Transformer) 모델 아키텍처 상세 정보**

BST 모델의 목표는 사용자의 과거 행동 '순서'에 담긴 동적인 신호를 포착하여 클릭률(CTR) 예측의 정확도를 높이는 것입니다.[1, 2] 이 모델은 크게 세 가지 핵심 구성요소로 이루어져 있습니다.[2]

#### **1. 임베딩 레이어 (Embedding Layer)**

이 단계에서는 모델에 입력되는 모든 특징을 저차원의 고정된 크기 벡터로 변환합니다. 입력은 크게 두 종류로 나뉩니다.

*   **기타 특징 (Other Features):**
    *   사용자의 행동 순서와 직접적인 관련이 없는 정적인 정보들을 포함합니다.[2]
    *   **포함되는 정보:** 사용자 프로필(성별, 나이 등), 타겟 아이템 정보(카테고리 ID 등), 문맥 정보(시간대 등), 그리고 이들의 조합으로 만들어진 교차 특징(Cross Features)이 해당됩니다.[2]
    *   **처리 방식:** 이 특징들은 모두 하나로 연결(concatenate)된 후, 임베딩 행렬을 통해 저차원 벡터로 변환됩니다.[2]

*   **행동 시퀀스 특징 (Behavior Sequence Features):**
    *   사용자가 과거에 클릭했던 아이템들의 순서 목록과 현재 추천할 타겟 아이템을 포함합니다.[2, 3]
    *   각 아이템은 두 가지 유형의 특징으로 표현됩니다 [2, 4]:
        1.  **시퀀스 아이템 특징 (Sequence Item Features):** 아이템 고유의 속성을 나타내며, 주로 `item_id`와 `category_id`가 사용됩니다.[2, 3, 4]
        2.  **위치 특징 (Positional Features):** 시퀀스 내 아이템의 순서 정보를 모델에 주입하기 위한 핵심 요소입니다. 원본 트랜스포머 논문의 sin/cos 함수 대신, BST는 **추천 시점과 사용자가 해당 아이템을 클릭했던 시점 간의 시간 차이**를 계산하여 위치 값으로 사용합니다. 이 방식이 더 나은 성능을 보인다고 보고되었습니다.[2]
    *   **처리 방식:** 각 아이템에 대해 '시퀀스 아이템 특징'과 '위치 특징'을 결합한 후, 별도의 임베딩 행렬을 통해 아이템 임베딩 벡터를 생성합니다.[2]

#### **2. 트랜스포머 레이어 (Transformer Layer)**

이 레이어는 BST 모델의 핵심으로, 임베딩된 아이템 시퀀스를 입력받아 아이템 간의 순차적 관계를 학습합니다.[2, 4]

*   **핵심 메커니즘 (Self-Attention):**
    *   트랜스포머의 셀프 어텐션 메커니즘은 시퀀스 내의 한 아이템이 다른 모든 아이템과 얼마나 관련이 있는지를 계산합니다.[2]
    *   이를 위해 각 아이템 임베딩으로부터 쿼리(Query), 키(Key), 값(Value)이라는 세 개의 벡터를 생성하고, 스케일드 닷-프로덕트 어텐션(Scaled Dot-Product Attention)을 수행합니다.[2]
    *   특히, 여러 개의 어텐션을 병렬로 수행하는 **멀티-헤드 어텐션(Multi-Head Attention)**을 사용하여 다양한 관점의 관계를 동시에 학습합니다.[2]

*   **보조 구성요소:**
    *   **Point-wise Feed-Forward Network (FFN):** 어텐션 레이어의 출력에 비선형성을 더해 모델의 표현력을 높입니다.[2]
    *   **정규화 및 잔차 연결:** 각 하위 레이어(셀프 어텐션, FFN)마다 드롭아웃(Dropout), LeakyReLU, 레이어 정규화(LayerNorm) 등을 적용하여 과적합을 방지하고 안정적인 학습을 돕습니다.[2, 4]

*   **레이어 스태킹(Stacking):**
    *   이론적으로 트랜스포머 블록을 여러 겹 쌓아 더 복잡한 관계를 학습할 수 있습니다.
    *   하지만 원본 논문의 실험 결과에 따르면, CTR 예측 문제에서는 **하나의 블록(b=1)을 사용했을 때**가 2~3개를 쌓았을 때보다 더 좋은 성능을 보였습니다. 이는 사용자 행동 시퀀스의 의존성이 기계 번역의 문장만큼 복잡하지 않기 때문일 수 있습니다.[2, 4]

#### **3. MLP 레이어 및 손실 함수 (MLP Layers and Loss function)**

트랜스포머 레이어를 거친 시퀀스 표현을 다른 특징들과 결합하여 최종 예측을 수행하는 단계입니다.

*   **결합 (Concatenation):**
    *   트랜스포머 레이어의 여러 출력 벡터 중, **오직 타겟 아이템(Target Item)에 해당하는 출력 벡터**만을 선택합니다.[2]
    *   이 타겟 아이템 벡터를 1단계에서 임베딩된 **'기타 특징(Other Features)' 벡터와 연결(concatenate)**합니다.[2, 3, 4]

*   **예측:**
    *   결합된 벡터는 3개의 은닉층으로 구성된 표준적인 다층 퍼셉트론(MLP)에 입력됩니다. 이 MLP는 모든 특징 간의 최종적인 상호작용을 학습합니다.[2, 3, 4]
    *   마지막 출력층에서는 **시그모이드(Sigmoid) 활성화 함수**를 사용하여 사용자가 타겟 아이템을 클릭할 확률(0과 1 사이의 값)을 예측합니다.[2, 4]

*   **손실 함수:**
    *   모델 학습은 이진 분류 문제로 정의되므로, **교차 엔트로피(Cross-Entropy) 손실 함수**를 사용하여 모델의 예측값과 실제 레이블(클릭 여부) 간의 차이를 최소화하는 방향으로 파라미터를 업데이트합니다.[2]