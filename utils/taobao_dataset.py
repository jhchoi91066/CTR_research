"""
Taobao ë°ì´í„°ì…‹ ë¡œë”
"""

import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import pickle
from pathlib import Path


class TaobaoDataset(Dataset):
    """Taobao UserBehavior CTR ë°ì´í„°ì…‹"""

    def __init__(self, data_path, metadata_path):
        """
        Args:
            data_path: train/val/test.parquet ê²½ë¡œ
            metadata_path: metadata.pkl ê²½ë¡œ
        """
        self.data = pd.read_parquet(data_path)

        with open(metadata_path, 'rb') as f:
            self.metadata = pickle.load(f)

        print(f"âœ… Taobao ë°ì´í„°ì…‹ ë¡œë”© ì™„ë£Œ")
        print(f"   - ë°ì´í„° í¬ê¸°: {len(self.data):,} rows")
        print(f"   - ì‚¬ìš©ì ìˆ˜: {self.data['user_id_encoded'].nunique():,}")
        print(f"   - ìƒí’ˆ ìˆ˜: {self.data['item_id_encoded'].nunique():,}")
        print(f"   - Max sequence length: {self.metadata['max_seq_len']}")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        """
        Returns:
            target_item: int - íƒ€ê²Ÿ ì•„ì´í…œ ID
            target_category: int - íƒ€ê²Ÿ ì¹´í…Œê³ ë¦¬ ID
            item_history: Tensor (max_seq_len,) - ì•„ì´í…œ íˆìŠ¤í† ë¦¬
            category_history: Tensor (max_seq_len,) - ì¹´í…Œê³ ë¦¬ íˆìŠ¤í† ë¦¬ â­ ì¶”ê°€
            other_features: Dict - {feature_name: value}
            label: Tensor - ë ˆì´ë¸”
        """
        row = self.data.iloc[idx]

        # Target item & category
        target_item = int(row['item_id_encoded'])
        target_category = int(row['category_id_encoded'])

        # Item history sequence
        item_history = torch.tensor(row['item_history'], dtype=torch.long)
        category_history = torch.tensor(row['category_history'], dtype=torch.long)  # â­ ì¶”ê°€

        # Other features
        other_features = {
            'user_id': int(row['user_id_encoded']),
            'hour': int(row['hour']),
            'dayofweek': int(row['dayofweek'])
        }

        # Label
        label = torch.tensor(row['label'], dtype=torch.float32)

        return target_item, target_category, item_history, category_history, other_features, label


def collate_fn(batch):
    """
    ë°°ì¹˜ ë°ì´í„° ë¬¶ê¸°

    Args:
        batch: List of (target_item, target_category, item_history, category_history, other_features, label)

    Returns:
        target_items: Tensor (batch_size,)
        target_categories: Tensor (batch_size,)
        item_histories: Tensor (batch_size, max_seq_len)
        category_histories: Tensor (batch_size, max_seq_len) â­ ì¶”ê°€
        other_features: Dict of {feat_name: Tensor (batch_size,)}
        labels: Tensor (batch_size,)
    """
    target_items, target_categories, item_histories, category_histories, other_features_list, labels = zip(*batch)

    # Stack target items & categories
    target_items = torch.tensor(target_items, dtype=torch.long)
    target_categories = torch.tensor(target_categories, dtype=torch.long)

    # Stack item histories
    item_histories = torch.stack(item_histories)
    category_histories = torch.stack(category_histories)  # â­ ì¶”ê°€

    # Combine other features
    other_features = {}
    for key in other_features_list[0].keys():
        other_features[key] = torch.tensor(
            [item[key] for item in other_features_list],
            dtype=torch.long
        )

    # Stack labels
    labels = torch.stack(labels)

    return target_items, target_categories, item_histories, category_histories, other_features, labels


def get_taobao_dataloader(data_path, metadata_path, batch_size=1024, shuffle=True, num_workers=0):
    """
    Taobao DataLoader ìƒì„±

    Args:
        data_path: train/val/test.parquet ê²½ë¡œ
        metadata_path: metadata.pkl ê²½ë¡œ
        batch_size: ë°°ì¹˜ í¬ê¸°
        shuffle: ì…”í”Œ ì—¬ë¶€
        num_workers: ì›Œì»¤ ìˆ˜

    Returns:
        DataLoader, metadata
    """
    dataset = TaobaoDataset(data_path, metadata_path)

    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=False  # MPSì—ì„œëŠ” pin_memory ì‚¬ìš© ì•ˆí•¨
    )

    return dataloader, dataset.metadata


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    print("="*60)
    print("ğŸ§ª Taobao ë°ì´í„°ì…‹ ë¡œë” í…ŒìŠ¤íŠ¸")
    print("="*60)

    data_dir = Path('data/processed/taobao')

    # DataLoader ìƒì„±
    train_loader, metadata = get_taobao_dataloader(
        data_path=data_dir / 'train.parquet',
        metadata_path=data_dir / 'metadata.pkl',
        batch_size=128,
        shuffle=True
    )

    # ì²« ë²ˆì§¸ ë°°ì¹˜ í™•ì¸
    target_items, target_categories, item_histories, category_histories, other_features, labels = next(iter(train_loader))

    print(f"\nğŸ“¦ ë°°ì¹˜ ì •ë³´:")
    print(f"   - Target items shape: {target_items.shape}")
    print(f"   - Target categories shape: {target_categories.shape}")
    print(f"   - Item histories shape: {item_histories.shape}")
    print(f"   - Category histories shape: {category_histories.shape}")  # â­ ì¶”ê°€
    print(f"   - Other features: {list(other_features.keys())}")
    print(f"   - Labels shape: {labels.shape}")
    print(f"   - Labels range: [{labels.min():.0f}, {labels.max():.0f}]")
    print(f"   - CTR: {labels.mean():.4f}")

    # ìƒ˜í”Œ í™•ì¸
    print(f"\nï¿½ï¿½ ìƒ˜í”Œ ë°ì´í„°:")
    print(f"   - Target item: {target_items[0].item()}")
    print(f"   - Target category: {target_categories[0].item()}")
    print(f"   - Item history: {item_histories[0].tolist()}")
    print(f"   - Category history: {category_histories[0].tolist()}")  # â­ ì¶”ê°€
    print(f"   - User ID: {other_features['user_id'][0].item()}")
    print(f"   - Hour: {other_features['hour'][0].item()}")
    print(f"   - Label: {labels[0].item()}")

    print("\n" + "="*60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*60)
