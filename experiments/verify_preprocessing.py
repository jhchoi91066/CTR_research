"""
ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

Usage:
    python experiments/verify_preprocessing.py
"""

import pandas as pd
import pickle
from pathlib import Path


def verify_preprocessing(data_dir='data/processed'):
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° ê²€ì¦"""
    data_dir = Path(data_dir)

    print("="*60)
    print("ğŸ” ì „ì²˜ë¦¬ ë°ì´í„° ê²€ì¦")
    print("="*60)

    # 1. íŒŒì¼ ì¡´ì¬ í™•ì¸
    print("\n1ï¸âƒ£ íŒŒì¼ ì¡´ì¬ í™•ì¸:")
    required_files = ['train.parquet', 'val.parquet', 'test.parquet', 'metadata.pkl']
    for file in required_files:
        file_path = data_dir / file
        if file_path.exists():
            size_mb = file_path.stat().st_size / 1024**2
            print(f"   âœ… {file}: {size_mb:.2f} MB")
        else:
            print(f"   âŒ {file}: íŒŒì¼ ì—†ìŒ")

    # 2. ë©”íƒ€ë°ì´í„° ë¡œë”©
    print("\n2ï¸âƒ£ ë©”íƒ€ë°ì´í„° í™•ì¸:")
    with open(data_dir / 'metadata.pkl', 'rb') as f:
        metadata = pickle.load(f)

    print(f"   - ìˆ˜ì¹˜í˜• íŠ¹ì§•: {len(metadata['num_features'])}ê°œ")
    print(f"   - ë²”ì£¼í˜• íŠ¹ì§•: {len(metadata['cat_features'])}ê°œ")
    print(f"   - ë¹ˆë„ ì„ê³„ê°’: {metadata['freq_threshold']}")
    print(f"   - Vocabulary í¬ê¸° (ìƒìœ„ 5ê°œ):")
    for col, size in list(metadata['cat_vocab'].items())[:5]:
        print(f"      {col}: {size}")

    # 3. ë°ì´í„° ë¡œë”© ë° ê²€ì¦
    print("\n3ï¸âƒ£ ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ê²€ì¦:")
    train = pd.read_parquet(data_dir / 'train.parquet')
    val = pd.read_parquet(data_dir / 'val.parquet')
    test = pd.read_parquet(data_dir / 'test.parquet')

    print(f"   - Train: {train.shape}")
    print(f"   - Val:   {val.shape}")
    print(f"   - Test:  {test.shape}")

    # 4. ê²°ì¸¡ì¹˜ í™•ì¸
    print("\n4ï¸âƒ£ ê²°ì¸¡ì¹˜ í™•ì¸:")
    for name, df in [('Train', train), ('Val', val), ('Test', test)]:
        missing = df.isnull().sum().sum()
        print(f"   - {name}: {missing}ê°œ (ì „ì²´ì˜ {missing/df.size*100:.4f}%)")

    # 5. ë¼ë²¨ ë¶„í¬ í™•ì¸
    print("\n5ï¸âƒ£ ë¼ë²¨ ë¶„í¬:")
    for name, df in [('Train', train), ('Val', val), ('Test', test)]:
        ctr = df['label'].mean()
        print(f"   - {name} CTR: {ctr:.4%}")

    # 6. ìˆ˜ì¹˜í˜• íŠ¹ì§• ë²”ìœ„ í™•ì¸
    print("\n6ï¸âƒ£ ìˆ˜ì¹˜í˜• íŠ¹ì§• í†µê³„ (Train):")
    num_stats = train[metadata['num_features']].describe()
    print(num_stats)

    # 7. ë²”ì£¼í˜• íŠ¹ì§• ë²”ìœ„ í™•ì¸
    print("\n7ï¸âƒ£ ë²”ì£¼í˜• íŠ¹ì§• ê³ ìœ ê°’ ê°œìˆ˜ (Train):")
    cat_nunique = train[metadata['cat_features']].nunique()
    print(cat_nunique)

    print("\n" + "="*60)
    print("âœ… ê²€ì¦ ì™„ë£Œ!")
    print("="*60)

    return train, val, test, metadata


if __name__ == '__main__':
    verify_preprocessing()
