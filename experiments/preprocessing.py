"""
Criteo ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

ì „ì²˜ë¦¬ ë‹¨ê³„:
1. ë°ì´í„° ë¡œë”© (ì²­í¬ ë‹¨ìœ„)
2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•: median, ë²”ì£¼í˜•: 'missing')
3. ìˆ˜ì¹˜í˜• íŠ¹ì§• ë¡œê·¸ ë³€í™˜
4. ë²”ì£¼í˜• íŠ¹ì§• ë¹ˆë„ í•„í„°ë§ ë° ì¸ì½”ë”©
5. Train/Val/Test ë¶„í• 
6. ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ (.parquet)

Usage:
    python experiments/preprocessing.py --sample_size 1000000
    python experiments/preprocessing.py --full  # ì „ì²´ ë°ì´í„°
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import argparse
import os
from pathlib import Path
from tqdm import tqdm
import pickle


class CriteoPreprocessor:
    """Criteo ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, data_path, output_dir, sample_size=None, freq_threshold=10):
        """
        Args:
            data_path: train.txt ê²½ë¡œ
            output_dir: ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ê²½ë¡œ
            sample_size: ìƒ˜í”Œë§ í¬ê¸° (Noneì´ë©´ ì „ì²´ ë°ì´í„°)
            freq_threshold: ë²”ì£¼í˜• íŠ¹ì§• ë¹ˆë„ ì„ê³„ê°’
        """
        self.data_path = data_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.sample_size = sample_size
        self.freq_threshold = freq_threshold

        # ì»¬ëŸ¼ëª… ì •ì˜
        self.num_features = [f'I{i}' for i in range(1, 14)]
        self.cat_features = [f'C{i}' for i in range(1, 27)]
        self.columns = ['label'] + self.num_features + self.cat_features

        # ì „ì²˜ë¦¬ì— í•„ìš”í•œ í†µê³„ ì €ì¥
        self.num_medians = {}
        self.cat_encoders = {}
        self.cat_vocab = {}

        print(f"âœ… Preprocessor ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - ë°ì´í„° ê²½ë¡œ: {self.data_path}")
        print(f"   - ì¶œë ¥ ê²½ë¡œ: {self.output_dir}")
        print(f"   - ìƒ˜í”Œ í¬ê¸°: {self.sample_size if self.sample_size else 'ì „ì²´'}")
        print(f"   - ë¹ˆë„ ì„ê³„ê°’: {self.freq_threshold}")

    def load_data(self):
        """ë°ì´í„° ë¡œë”©"""
        print(f"\nğŸ“¥ ë°ì´í„° ë¡œë”© ì¤‘...")

        df = pd.read_csv(
            self.data_path,
            sep='\t',
            header=None,
            names=self.columns,
            nrows=self.sample_size
        )

        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {df.shape}")
        print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        print(f"   - CTR: {df['label'].mean():.4%}")

        return df

    def handle_missing_values(self, df):
        """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
        print(f"\nğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...")

        # ìˆ˜ì¹˜í˜•: medianìœ¼ë¡œ ëŒ€ì²´
        for col in tqdm(self.num_features, desc="ìˆ˜ì¹˜í˜• íŠ¹ì§•"):
            median_val = df[col].median()
            self.num_medians[col] = median_val
            df[col].fillna(median_val, inplace=True)

        # ë²”ì£¼í˜•: 'missing' ë¬¸ìì—´ë¡œ ëŒ€ì²´
        for col in tqdm(self.cat_features, desc="ë²”ì£¼í˜• íŠ¹ì§•"):
            df[col].fillna('missing', inplace=True)

        print(f"âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
        print(f"   - ìˆ˜ì¹˜í˜• median ê°’: {len(self.num_medians)}ê°œ ì €ì¥")

        return df

    def transform_numeric_features(self, df):
        """ìˆ˜ì¹˜í˜• íŠ¹ì§• ë¡œê·¸ ë³€í™˜"""
        print(f"\nğŸ”§ ìˆ˜ì¹˜í˜• íŠ¹ì§• ë¡œê·¸ ë³€í™˜ ì¤‘...")

        for col in tqdm(self.num_features, desc="ë¡œê·¸ ë³€í™˜"):
            # ìŒìˆ˜ ê°’ ì²˜ë¦¬ í›„ ë¡œê·¸ ë³€í™˜
            df[col] = np.log1p(df[col].clip(lower=0))

        print(f"âœ… ë¡œê·¸ ë³€í™˜ ì™„ë£Œ")

        return df

    def encode_categorical_features(self, df):
        """ë²”ì£¼í˜• íŠ¹ì§• ì¸ì½”ë”©"""
        print(f"\nğŸ”§ ë²”ì£¼í˜• íŠ¹ì§• ì¸ì½”ë”© ì¤‘...")

        for col in tqdm(self.cat_features, desc="ë²”ì£¼í˜• ì¸ì½”ë”©"):
            # ë¹ˆë„ ê³„ì‚°
            value_counts = df[col].value_counts()

            # ë¹ˆë„ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê°’ë§Œ ìœ ì§€, ë‚˜ë¨¸ì§€ëŠ” '<unk>'ë¡œ ë³€í™˜
            valid_values = value_counts[value_counts >= self.freq_threshold].index.tolist()
            df[col] = df[col].apply(lambda x: x if x in valid_values else '<unk>')

            # Label Encoding
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col].astype(str))

            # ì¸ì½”ë” ë° vocab ì €ì¥
            self.cat_encoders[col] = le
            self.cat_vocab[col] = len(le.classes_)

        print(f"âœ… ë²”ì£¼í˜• ì¸ì½”ë”© ì™„ë£Œ")
        print(f"   - Vocabulary í¬ê¸°:")
        for col, vocab_size in list(self.cat_vocab.items())[:5]:
            print(f"      {col}: {vocab_size}")
        print(f"      ... (ì´ {len(self.cat_vocab)}ê°œ)")

        return df

    def split_data(self, df, test_size=0.2, val_size=0.1):
        """Train/Val/Test ë¶„í• """
        print(f"\nğŸ”§ ë°ì´í„° ë¶„í•  ì¤‘...")

        # Train + Val vs Test
        train_val, test = train_test_split(
            df, test_size=test_size, random_state=42, stratify=df['label']
        )

        # Train vs Val
        val_ratio = val_size / (1 - test_size)
        train, val = train_test_split(
            train_val, test_size=val_ratio, random_state=42, stratify=train_val['label']
        )

        print(f"âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ")
        print(f"   - Train: {len(train):,} ({len(train)/len(df)*100:.1f}%)")
        print(f"   - Val:   {len(val):,} ({len(val)/len(df)*100:.1f}%)")
        print(f"   - Test:  {len(test):,} ({len(test)/len(df)*100:.1f}%)")

        return train, val, test

    def save_data(self, train, val, test):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        print(f"\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")

        # Parquet í˜•ì‹ìœ¼ë¡œ ì €ì¥
        train.to_parquet(self.output_dir / 'train.parquet', index=False)
        val.to_parquet(self.output_dir / 'val.parquet', index=False)
        test.to_parquet(self.output_dir / 'test.parquet', index=False)

        # ì „ì²˜ë¦¬ ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'num_medians': self.num_medians,
            'cat_encoders': self.cat_encoders,
            'cat_vocab': self.cat_vocab,
            'num_features': self.num_features,
            'cat_features': self.cat_features,
            'freq_threshold': self.freq_threshold
        }

        with open(self.output_dir / 'metadata.pkl', 'wb') as f:
            pickle.dump(metadata, f)

        print(f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        print(f"   - ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
        print(f"   - íŒŒì¼:")
        for file in ['train.parquet', 'val.parquet', 'test.parquet', 'metadata.pkl']:
            file_path = self.output_dir / file
            if file_path.exists():
                size_mb = file_path.stat().st_size / 1024**2
                print(f"      {file}: {size_mb:.2f} MB")

    def run(self):
        """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("="*60)
        print("ğŸš€ Criteo ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("="*60)

        # 1. ë°ì´í„° ë¡œë”©
        df = self.load_data()

        # 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = self.handle_missing_values(df)

        # 3. ìˆ˜ì¹˜í˜• íŠ¹ì§• ë³€í™˜
        df = self.transform_numeric_features(df)

        # 4. ë²”ì£¼í˜• íŠ¹ì§• ì¸ì½”ë”©
        df = self.encode_categorical_features(df)

        # 5. ë°ì´í„° ë¶„í• 
        train, val, test = self.split_data(df)

        # 6. ë°ì´í„° ì €ì¥
        self.save_data(train, val, test)

        print("\n" + "="*60)
        print("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print("="*60)
        print(f"\në‹¤ìŒ ë‹¨ê³„:")
        print(f"  1. python experiments/verify_preprocessing.py  # ë°ì´í„° ê²€ì¦")
        print(f"  2. ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ êµ¬í˜„ ì‹œì‘")

        return train, val, test


def main():
    parser = argparse.ArgumentParser(description='Criteo ë°ì´í„° ì „ì²˜ë¦¬')
    parser.add_argument('--data_path', type=str,
                        default='data/raw/dac/train.txt',
                        help='train.txt ê²½ë¡œ')
    parser.add_argument('--output_dir', type=str,
                        default='data/processed',
                        help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--sample_size', type=int, default=1_000_000,
                        help='ìƒ˜í”Œ í¬ê¸° (ì „ì²´ ì‚¬ìš©ì‹œ --full ì˜µì…˜)')
    parser.add_argument('--full', action='store_true',
                        help='ì „ì²´ ë°ì´í„° ì‚¬ìš©')
    parser.add_argument('--freq_threshold', type=int, default=10,
                        help='ë²”ì£¼í˜• íŠ¹ì§• ë¹ˆë„ ì„ê³„ê°’')

    args = parser.parse_args()

    # ì „ì²´ ë°ì´í„° ì‚¬ìš© ì˜µì…˜
    sample_size = None if args.full else args.sample_size

    # ì „ì²˜ë¦¬ ì‹¤í–‰
    preprocessor = CriteoPreprocessor(
        data_path=args.data_path,
        output_dir=args.output_dir,
        sample_size=sample_size,
        freq_threshold=args.freq_threshold
    )

    preprocessor.run()


if __name__ == '__main__':
    main()
