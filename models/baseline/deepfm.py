"""
DeepFM: Factorization Machine + Deep Neural Network

Reference:
    Guo et al. "DeepFM: A Factorization-Machine based Neural Network
    for CTR Prediction" (IJCAI 2017)

Architecture:
    Input â†’ Embedding (shared) â†’ [Linear + FM + DNN] â†’ Sigmoid â†’ Output

ë…¼ë¬¸ ìˆ˜ì‹:
    y_hat = sigmoid(y_FM + y_DNN)
    where:
        y_FM = <w, x> + Î£_i Î£_j <V_i, V_j> x_i x_j  (1st-order + 2nd-order)
        y_DNN = MLP(a^0) where a^0 = [e_1, e_2, ..., e_m]

í•µì‹¬: FMê³¼ DNNì´ ë™ì¼í•œ embedding Vë¥¼ ê³µìœ 
"""

import torch
import torch.nn as nn


class FactorizationMachine(nn.Module):
    """
    Factorization Machine component

    ë…¼ë¬¸ ìˆ˜ì‹ (2nd-order interaction):
        Î£_i Î£_j <V_i, V_j> x_i x_j
        = 1/2 Î£_f=1^k ((Î£_i v_i,f x_i)^2 - Î£_i v_i,f^2 x_i^2)
    """

    def __init__(self):
        super(FactorizationMachine, self).__init__()

    def forward(self, embeddings):
        """
        Args:
            embeddings: (batch_size, num_fields, embed_dim)
                ê° fieldì˜ embedding vector V_i

        Returns:
            fm_output: (batch_size, 1) - FMì˜ 2ì°¨ ìƒí˜¸ì‘ìš© í•­
        """
        # ë…¼ë¬¸ ìˆ˜ì‹ ê·¸ëŒ€ë¡œ êµ¬í˜„
        # square_of_sum: (Î£_i V_i)^2
        square_of_sum = torch.sum(embeddings, dim=1) ** 2  # (batch, embed_dim)

        # sum_of_square: Î£_i (V_i)^2
        sum_of_square = torch.sum(embeddings ** 2, dim=1)  # (batch, embed_dim)

        # FM 2ì°¨ ìƒí˜¸ì‘ìš©: 0.5 * Î£_f ((Î£_i v_i,f)^2 - Î£_i v_i,f^2)
        fm_output = 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)

        return fm_output  # (batch, 1)


class DeepNeuralNetwork(nn.Module):
    """
    Deep Neural Network component

    ë…¼ë¬¸ ìˆ˜ì‹:
        a^(l+1) = Ïƒ(W^l a^l + b^l)
        where a^0 = [e_1, e_2, ..., e_m] (concatenated embeddings)
        y_DNN = Ïƒ(W^|H| a^|H| + b^|H|)
    """

    def __init__(self, input_dim, hidden_units=[256, 128, 64], dropout=0.1):
        """
        Args:
            input_dim: Input dimension (num_fields * embed_dim)
            hidden_units: List of hidden layer sizes (ë…¼ë¬¸ì˜ H)
            dropout: Dropout rate
        """
        super(DeepNeuralNetwork, self).__init__()

        layers = []
        in_dim = input_dim

        # ë…¼ë¬¸ì˜ Hidden layers
        for hidden_dim in hidden_units:
            layers.append(nn.Linear(in_dim, hidden_dim))
            layers.append(nn.BatchNorm1d(hidden_dim))
            layers.append(nn.ReLU())  # ë…¼ë¬¸ì˜ activation function Ïƒ
            layers.append(nn.Dropout(dropout))
            in_dim = hidden_dim

        self.dnn = nn.Sequential(*layers)
        self.output_layer = nn.Linear(in_dim, 1)  # ë…¼ë¬¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´

    def forward(self, embeddings):
        """
        Args:
            embeddings: (batch_size, num_fields, embed_dim)
                ë…¼ë¬¸ì˜ a^0 = [e_1, e_2, ..., e_m]

        Returns:
            dnn_output: (batch_size, 1) - y_DNN
        """
        batch_size = embeddings.size(0)

        # Flatten embeddings: a^0
        x = embeddings.view(batch_size, -1)  # (batch, num_fields * embed_dim)

        # DNN forward: a^1, a^2, ..., a^|H|
        x = self.dnn(x)

        # Output: y_DNN
        dnn_output = self.output_layer(x)  # (batch, 1)

        return dnn_output


class DeepFM(nn.Module):
    """
    DeepFM Model (ë…¼ë¬¸ ì •í™•í•œ êµ¬í˜„)

    ë…¼ë¬¸ ìˆ˜ì‹:
        y_hat = sigmoid(y_FM + y_DNN)
        where:
            y_FM = <w, x> + Î£_i Î£_j <V_i, V_j> x_i x_j
            y_DNN = MLP([e_1, e_2, ..., e_m])

    í•µì‹¬:
        - FMê³¼ DNNì´ ë™ì¼í•œ embedding layer Vë¥¼ ê³µìœ 
        - 1st-orderëŠ” ë³„ë„ì˜ weight w
        - 2nd-orderëŠ” embedding interaction
    """

    def __init__(self,
                 num_features,
                 cat_vocab_sizes,
                 embed_dim=16,
                 hidden_units=[256, 128, 64],
                 dropout=0.1):
        """
        Args:
            num_features: Number of numeric features
            cat_vocab_sizes: Dict of {feature_name: vocab_size}
            embed_dim: Embedding dimension (ë…¼ë¬¸ì˜ k)
            hidden_units: DNN hidden layer sizes
            dropout: Dropout rate
        """
        super(DeepFM, self).__init__()

        self.num_features = num_features
        self.cat_vocab_sizes = cat_vocab_sizes
        self.embed_dim = embed_dim

        # ========== Shared Embeddings (í•µì‹¬!) ==========
        # ë…¼ë¬¸: "FM and DNN share the same feature embedding"

        # Numeric features â†’ embedding (treating as one field)
        self.numeric_embed = nn.Linear(num_features, embed_dim)

        # Categorical features â†’ embeddings
        self.cat_embeddings = nn.ModuleDict({
            feat: nn.Embedding(vocab_size, embed_dim)
            for feat, vocab_size in cat_vocab_sizes.items()
        })

        # ========== 1st-order weights (Linear part) ==========
        # ë…¼ë¬¸: <w, x>
        # ê° fieldë§ˆë‹¤ scalar weight
        num_fields = 1 + len(cat_vocab_sizes)  # numeric + categorical
        self.first_order_weights = nn.Embedding(num_fields, 1)
        self.first_order_bias = nn.Parameter(torch.zeros((1,)))

        # ========== FM component (2nd-order) ==========
        self.fm = FactorizationMachine()

        # ========== DNN component ==========
        dnn_input_dim = num_fields * embed_dim
        self.dnn = DeepNeuralNetwork(dnn_input_dim, hidden_units, dropout)

        # Weight initialization (ë…¼ë¬¸ ì°¸ê³ )
        self._initialize_weights()

        print(f"âœ… DeepFM ì´ˆê¸°í™” ì™„ë£Œ (ë…¼ë¬¸ ì •í™• êµ¬í˜„)")
        print(f"   - ìˆ˜ì¹˜í˜• íŠ¹ì§•: {num_features}ê°œ")
        print(f"   - ë²”ì£¼í˜• íŠ¹ì§•: {len(cat_vocab_sizes)}ê°œ")
        print(f"   - Total fields: {num_fields}")
        print(f"   - Embedding ì°¨ì›: {embed_dim}")
        print(f"   - DNN êµ¬ì¡°: {hidden_units}")

    def _initialize_weights(self):
        """Weight initialization"""
        # Embedding uniform initialization
        nn.init.xavier_uniform_(self.first_order_weights.weight)

    def forward(self, numeric_features, categorical_features):
        """
        ë…¼ë¬¸ ìˆ˜ì‹ ê·¸ëŒ€ë¡œ êµ¬í˜„:
            y_hat = sigmoid(y_FM + y_DNN)
            where y_FM = y_linear + y_interaction

        Args:
            numeric_features: (batch_size, num_features)
            categorical_features: Dict of {feat_name: (batch_size,)}

        Returns:
            output: (batch_size, 1) - CTR ì˜ˆì¸¡ê°’
        """
        batch_size = numeric_features.size(0)

        # ========== Shared Embeddings (FM & DNN ê³µìœ ) ==========
        embeddings_list = []
        field_indices = []

        # Field 0: Numeric features
        numeric_embed = self.numeric_embed(numeric_features).unsqueeze(1)  # (batch, 1, embed_dim)
        embeddings_list.append(numeric_embed)
        field_indices.append(torch.zeros(batch_size, dtype=torch.long, device=numeric_features.device))

        # Field 1~m: Categorical features
        for field_idx, feat_name in enumerate(sorted(self.cat_embeddings.keys()), start=1):
            feat_idx = categorical_features[feat_name]  # (batch,)
            cat_embed = self.cat_embeddings[feat_name](feat_idx).unsqueeze(1)  # (batch, 1, embed_dim)
            embeddings_list.append(cat_embed)
            field_indices.append(torch.full((batch_size,), field_idx, dtype=torch.long, device=numeric_features.device))

        # Concatenate all embeddings
        embeddings = torch.cat(embeddings_list, dim=1)  # (batch, num_fields, embed_dim)
        field_indices = torch.stack(field_indices, dim=1)  # (batch, num_fields)

        # ========== 1st-order: y_linear = <w, x> + b ==========
        # ê° fieldì˜ weightë¥¼ ê°€ì ¸ì™€ì„œ sum
        first_order = self.first_order_weights(field_indices)  # (batch, num_fields, 1)
        first_order = torch.sum(first_order, dim=1) + self.first_order_bias  # (batch, 1)

        # ========== 2nd-order: y_interaction = Î£_i Î£_j <V_i, V_j> x_i x_j ==========
        second_order = self.fm(embeddings)  # (batch, 1)

        # ========== y_FM = y_linear + y_interaction ==========
        y_fm = first_order + second_order  # (batch, 1)

        # ========== y_DNN = MLP(embeddings) ==========
        y_dnn = self.dnn(embeddings)  # (batch, 1)

        # ========== ìµœì¢… ì¶œë ¥: y_hat = sigmoid(y_FM + y_DNN) ==========
        logit = y_fm + y_dnn  # (batch, 1)
        output = torch.sigmoid(logit)

        return output

    def predict(self, numeric_features, categorical_features):
        """Inference mode"""
        self.eval()
        with torch.no_grad():
            output = self.forward(numeric_features, categorical_features)
        return output


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    print("="*60)
    print("ğŸ§ª DeepFM ë‹¨ìœ„ í…ŒìŠ¤íŠ¸")
    print("="*60)

    # ë”ë¯¸ ë°ì´í„°
    batch_size = 32
    num_features = 13
    cat_vocab_sizes = {
        f'C{i}': 100 + i * 10 for i in range(1, 27)
    }

    # ëª¨ë¸ ìƒì„±
    model = DeepFM(
        num_features=num_features,
        cat_vocab_sizes=cat_vocab_sizes,
        embed_dim=16,
        hidden_units=[256, 128, 64],
        dropout=0.1
    )

    # ë”ë¯¸ ì…ë ¥
    numeric_input = torch.randn(batch_size, num_features)
    categorical_input = {
        f'C{i}': torch.randint(0, 100 + i * 10, (batch_size,))
        for i in range(1, 27)
    }

    # Forward pass
    print(f"\nğŸ“¥ ì…ë ¥:")
    print(f"   - Numeric: {numeric_input.shape}")
    print(f"   - Categorical: {len(categorical_input)} features")

    output = model(numeric_input, categorical_input)

    print(f"\nğŸ“¤ ì¶œë ¥:")
    print(f"   - Shape: {output.shape}")
    print(f"   - Range: [{output.min().item():.4f}, {output.max().item():.4f}]")
    print(f"   - Mean: {output.mean().item():.4f}")

    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"\nğŸ“Š ëª¨ë¸ ì •ë³´:")
    print(f"   - ì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
    print(f"   - í•™ìŠµ ê°€ëŠ¥: {trainable_params:,}")

    print("\n" + "="*60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*60)
